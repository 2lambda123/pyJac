#include <stdlib.h>
#include <stdio.h>
#include <string.h>
#include "jacob.cuh"


#include <cuda.h>
#include <cuda_runtime.h>
#include <helper_cuda.h>
#include "header.cuh"
#include "timer.h"
#include "gpu_memory.cuh"
#include "launch_bounds.cuh"

int read_initial_conditions(const char*, int, double**, double**);

#define T_ID (threadIdx.x + (blockDim.x * blockIdx.x))
#define GRID_SIZE (blockDim.x * gridDim.x)
__global__
void jac_driver(int NUM, const double* pres, const double* y, const mechanism_memory* d_mem)
{
    if (T_ID < NUM)
    {
        eval_jacob (0, pres[T_ID], y, d_mem->jac, d_mem);
    }
}

inline void memcpy2D_in(double* dst, const int pitch_dst, double const * src, const int pitch_src,
                                     const int offset, const size_t width, const int height) {
    for (int i = 0; i < height; ++i)
    {
        memcpy(dst, &src[offset], width);
        dst += pitch_dst;
        src += pitch_src;
    }
}

int init_gpu_mem(double** y_device, double** var_device, mechanism_memory** h_mem, mechanism_memory**d_mem)
{
    //bytes per thread
    size_t mech_size = get_required_size();
    cudaDeviceProp props;
    cudaErrorCheck( cudaGetDeviceProperties(&props, device) );
    //memory size in bytes
    size_t mem_avail = props.totalGlobalMem;
    //conservatively estimate the maximum allowable threads
    int max_threads = int(floor(0.8 * float(mem_avail) / float(mech_size)));
    int padded = max_threads * block_size;

    initialize_gpu_memory(padded, h_mem, d_mem, y_device, var_device);
    return padded;
}

int main (int argc, char *argv[])
{
    int num_odes = 1;
    if (sscanf(argv[1], "%i", &num_odes) !=1 || (num_odes <= 0))
    {
        exit(1);
    }

    cudaErrorCheck (cudaSetDevice (0) );

    cudaErrorCheck(cudaDeviceSetCacheConfig(cudaFuncCachePreferL1));

    mechanism_memory * d_mem = 0;
    mechanism_memory* h_mem = (mechanism_memory*)malloc(sizeof(mechanism_memory));

    double* y_device;
    double* y_host;
    double* var_device;
    double* var_host;

    //padded is the number of threads allowable
    read_initial_conditions("$datafile", num_odes, &y_host, &var_host);
    int padded = init_gpu_mem(&y_device, &var_device, &h_mem, &d_mem);
    int g_num = (int)ceil(((double)padded) / ((double)TARGET_BLOCK_SIZE));
    if (g_num == 0)
        g_num = 1;
    dim3 dimGrid (g_num, 1 );
    dim3 dimBlock(TARGET_BLOCK_SIZE, 1);
    StartTimer();
    if (padded < num_odes)
    {
        double* y_temp = (double*)malloc(padded * NSP * sizeof(double));
        double* var_temp = (double*)malloc(padded * NSP * sizeof(double));
        int num_solved = 0;
        while (num_solved < num_odes)
        {
            int num_cond = min(num_odes - num_solved, padded);
            //copy our memory into y_temp and pres_temp
            memcpy2D_in(y_temp, padded, y_host, num_odes,
                            num_solved, num_cond * sizeof(double), NSP);
            memcpy(var_temp, &var_host[num_solved], num_cond * sizeof(double));
            cudaErrorCheck( cudaMemcpy (var_device, var_temp, padded * sizeof(double), cudaMemcpyHostToDevice));
            cudaErrorCheck( cudaMemcpy (y_device, y_temp, padded * NSP * sizeof(double), cudaMemcpyHostToDevice));
            #ifdef SHARED_SIZE
                jac_driver <<< dimGrid, dimBlock, SHARED_SIZE >>> (num_odes, var_device, y_device, d_mem);
            #else
                jac_driver <<< dimGrid, dimBlock >>> (num_odes, var_device, y_device, d_mem);
            #endif
            num_solved += num_cond;
        }
        free(y_temp);
        free(var_temp);
    }
    else
    {
        cudaErrorCheck( cudaMemcpy (var_device, var_host, padded * sizeof(double), cudaMemcpyHostToDevice));
        cudaErrorCheck( cudaMemcpy (y_device, y_host, padded * NSP * sizeof(double), cudaMemcpyHostToDevice));
        #ifdef SHARED_SIZE
            jac_driver <<< dimGrid, dimBlock, SHARED_SIZE >>> (num_odes, var_device, y_device, d_mem);
        #else
            jac_driver <<< dimGrid, dimBlock >>> (num_odes, var_device, y_device, d_mem);
        #endif
    }
    cudaDeviceSynchronize();
    double runtime = GetTimer();
    printf("%d,%.15le\n", num_odes, runtime);
    cudaErrorCheck( cudaPeekAtLastError() );
    cudaErrorCheck( cudaDeviceSynchronize() );
    free_gpu_memory(&h_mem, &d_mem, &y_device, &var_device);
    free(y_host);
    free(var_host);
    free(h_mem);
    cudaErrorCheck( cudaDeviceReset() );
    return 0;
}